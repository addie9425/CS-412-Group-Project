{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ec7829db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "677ad16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "repo = fetch_ucirepo(id=697)\n",
    "X = repo.data.features\n",
    "y = repo.data.targets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "13a08224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelComparison:\n",
    "    \n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def logistic_regression(self):\n",
    "        model = LogisticRegression(max_iter=10000)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        predictions = model.predict(self.X_test)\n",
    "        accuracy = accuracy_score(self.y_test, predictions)\n",
    "        return accuracy\n",
    "    \n",
    "    def svm(self):\n",
    "        model = SVC(kernel='linear')\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        predictions = model.predict(self.X_test)\n",
    "        accuracy = accuracy_score(self.y_test, predictions)\n",
    "        return accuracy\n",
    "    \n",
    "    def knn(self, k):\n",
    "        knn_X_train = np.asarray(self.X_train)\n",
    "        knn_X_test = np.asarray(self.X_test)\n",
    "        model = KNeighborsClassifier(n_neighbors=k)\n",
    "        model.fit(knn_X_train, y_train)\n",
    "        predictions = model.predict(knn_X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        return accuracy\n",
    "        \n",
    "    def evaluate(self):\n",
    "        print(f\"logregacc: {self.logistic_regression()}\")\n",
    "        print(f\"svmacc: {self.svm()}\")\n",
    "        for k in [1, 3, 5, 7, 9]:\n",
    "            print(f\"knn-{k}: {self.knn(k)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e14f6e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logregacc: 0.7502824858757062\n",
      "svmacc: 0.752542372881356\n",
      "knn-1: 0.5649717514124294\n",
      "knn-3: 0.5988700564971752\n",
      "knn-5: 0.6090395480225989\n",
      "knn-7: 0.5966101694915255\n",
      "knn-9: 0.6011299435028249\n"
     ]
    }
   ],
   "source": [
    "vanilla = ModelComparison(X_train, X_test, y_train, y_test)\n",
    "vanilla.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b8fa6074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logregacc: 0.7491525423728813\n",
      "svmacc: 0.7423728813559322\n",
      "knn-1: 0.6282485875706215\n",
      "knn-3: 0.6632768361581921\n",
      "knn-5: 0.6870056497175141\n",
      "knn-7: 0.6779661016949152\n",
      "knn-9: 0.6870056497175141\n"
     ]
    }
   ],
   "source": [
    "'''applying minmax feature scaling'''\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_test_minmax = min_max_scaler.transform(X_test)\n",
    "\n",
    "minmax = ModelComparison(X_train_minmax, X_test_minmax, y_train, y_test)\n",
    "minmax.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9756d0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logregacc: 0.768361581920904\n",
      "svmacc: 0.7559322033898305\n",
      "knn-1: 0.6305084745762712\n",
      "knn-3: 0.6644067796610169\n",
      "knn-5: 0.6677966101694915\n",
      "knn-7: 0.6734463276836158\n",
      "knn-9: 0.6937853107344633\n"
     ]
    }
   ],
   "source": [
    "'''applying sklearn standard feature scaling'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "\n",
    "std = ModelComparison(X_train_std, X_test_std, y_train, y_test)\n",
    "std.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "53ec8b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7593220338983051\n"
     ]
    }
   ],
   "source": [
    "'''L1 regularization for logistic regression models'''\n",
    "lr = LogisticRegression(penalty='l1',\n",
    "                       C=1.0,\n",
    "                       solver='liblinear',\n",
    "                       multi_class='ovr')\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "80a54ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2df7f708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logregacc: 0.7502824858757062\n",
      "svmacc: 0.752542372881356\n",
      "knn-1: 0.5649717514124294\n",
      "knn-3: 0.5988700564971752\n",
      "knn-5: 0.6090395480225989\n",
      "knn-7: 0.5966101694915255\n",
      "knn-9: 0.6011299435028249\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "76a852a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.0: 0.7005649717514124\n",
      "-3.0: 0.7412429378531074\n",
      "-2.0: 0.7457627118644068\n",
      "-1.0: 0.7638418079096045\n",
      "0.0: 0.7593220338983051\n",
      "1.0: 0.7638418079096045\n",
      "2.0: 0.7638418079096045\n",
      "3.0: 0.7604519774011299\n",
      "4.0: 0.7615819209039548\n",
      "5.0: 0.7627118644067796\n"
     ]
    }
   ],
   "source": [
    "'''Varying regularization strength by varying C'''\n",
    "for c in np.arange(-4., 6.):\n",
    "    lr = LogisticRegression(penalty='l2',\n",
    "                       C=10.**c,\n",
    "                       solver='liblinear',\n",
    "                       multi_class='ovr',\n",
    "                       random_state=42)\n",
    "    lr.fit(X_train, y_train)\n",
    "    predictions = lr.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"{c}: {accuracy}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2ea520d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curricular units 2nd sem (approved) 0.14251911655035635\n",
      "Curricular units 2nd sem (grade) 0.10304204177962786\n",
      "Curricular units 1st sem (approved) 0.09744701755827954\n",
      "Curricular units 1st sem (grade) 0.06443600957126977\n",
      "Curricular units 2nd sem (evaluations) 0.04290551807912366\n",
      "Tuition fees up to date 0.04275928457015821\n",
      "Admission grade 0.04219932756780902\n",
      "Previous qualification (grade) 0.037744396720256354\n",
      "Curricular units 1st sem (evaluations) 0.03608591810760967\n",
      "Age at enrollment 0.03562577054617887\n",
      "Course 0.033006553890450464\n",
      "Father's occupation 0.02909368048710706\n",
      "Mother's occupation 0.025796796750648825\n",
      "GDP 0.023500176431770523\n",
      "Curricular units 2nd sem (enrolled) 0.022047780891788556\n",
      "Unemployment rate 0.021709800975935136\n",
      "Father's qualification 0.02125354681135768\n",
      "Mother's qualification 0.020722141806487886\n",
      "Application mode 0.020715168315078976\n",
      "Inflation rate 0.02065063559298854\n",
      "Curricular units 1st sem (enrolled) 0.01812900581811509\n",
      "Scholarship holder 0.016914406546804567\n",
      "Application order 0.014927202609219162\n",
      "Debtor 0.010456907183902853\n",
      "Gender 0.009414161684830355\n",
      "Displaced 0.007703587293840533\n",
      "Curricular units 1st sem (credited) 0.006857087621164197\n",
      "Previous qualification 0.006108643589697174\n",
      "Curricular units 2nd sem (credited) 0.005508577509188738\n",
      "Curricular units 1st sem (without evaluations) 0.005066484661789797\n",
      "Curricular units 2nd sem (without evaluations) 0.004396579624094752\n",
      "Marital Status 0.003569236125856086\n",
      "Daytime/evening attendance 0.0028478121584421994\n",
      "Nacionality 0.002266365989405995\n",
      "International 0.0014633488854692862\n",
      "Educational special needs 0.0011099096938962912\n"
     ]
    }
   ],
   "source": [
    "'''use a random forest classifier to assess feature importance'''\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "features = X.columns\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X.shape[1]):\n",
    "    print(features[indices[f]], importances[indices[f]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5ad15f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''limit features to top four, eight, and sixteen most important features'''\n",
    "top_four = indices[:4]\n",
    "top_eight = indices[:8]\n",
    "top_sixteen = indices[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ed5571db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logregacc: 0.6903954802259887\n",
      "svmacc: 0.6915254237288135\n",
      "knn-1: 0.6508474576271186\n",
      "knn-3: 0.6813559322033899\n",
      "knn-5: 0.688135593220339\n",
      "knn-7: 0.6745762711864407\n",
      "knn-9: 0.6734463276836158\n",
      "logregacc: 0.7231638418079096\n",
      "svmacc: 0.7062146892655368\n",
      "knn-1: 0.615819209039548\n",
      "knn-3: 0.632768361581921\n",
      "knn-5: 0.6531073446327683\n",
      "knn-7: 0.6644067796610169\n",
      "knn-9: 0.6666666666666666\n",
      "logregacc: 0.751412429378531\n",
      "svmacc: 0.7536723163841808\n",
      "knn-1: 0.6056497175141243\n",
      "knn-3: 0.6440677966101694\n",
      "knn-5: 0.6338983050847458\n",
      "knn-7: 0.632768361581921\n",
      "knn-9: 0.6440677966101694\n",
      "logregacc: 0.7502824858757062\n",
      "svmacc: 0.7548022598870057\n",
      "knn-1: 0.5570621468926553\n",
      "knn-3: 0.5954802259887005\n",
      "knn-5: 0.6090395480225989\n",
      "knn-7: 0.5988700564971752\n",
      "knn-9: 0.6135593220338983\n",
      "logregacc: 0.7593220338983051\n",
      "svmacc: 0.7502824858757062\n",
      "knn-1: 0.5570621468926553\n",
      "knn-3: 0.5966101694915255\n",
      "knn-5: 0.6135593220338983\n",
      "knn-7: 0.6011299435028249\n",
      "knn-9: 0.607909604519774\n",
      "logregacc: 0.751412429378531\n",
      "svmacc: 0.7502824858757062\n",
      "knn-1: 0.5661016949152542\n",
      "knn-3: 0.5932203389830508\n",
      "knn-5: 0.6045197740112994\n",
      "knn-7: 0.5909604519774011\n",
      "knn-9: 0.592090395480226\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 36, 6):\n",
    "    new_X_train = X_train.iloc[:, list(indices[:i])]\n",
    "    new_X_test = X_test.iloc[:, list(indices[:i])] \n",
    "    model = ModelComparison(new_X_train, new_X_test, y_train, y_test)\n",
    "    model.evaluate()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2587c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''unsupervised dimensionality reduction with principal component analysis'''\n",
    "pca = PCA()\n",
    "lr = LogisticRegression(multi_class='ovr',\n",
    "                       random_state=1,\n",
    "                       solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "81a63d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7028248587570621\n"
     ]
    }
   ],
   "source": [
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "lr.fit(X_train_pca, y_train)\n",
    "predictions = lr.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1520e6a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=LinearDiscriminantAnalysis(n_components=2).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[207], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m lr \u001b[38;5;241m=\u001b[39m LogisticRegression(multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      6\u001b[0m                         solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m lr \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m----> 8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(X_test_lda)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test, predictions))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:932\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_2d:\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;66;03m# If input is scalar raise error\u001b[39;00m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 932\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got scalar array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    935\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    937\u001b[0m         )\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=LinearDiscriminantAnalysis(n_components=2).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "'''supervised data compression via linear discriminant analysis'''\n",
    "lda = LDA(n_components=2)\n",
    "X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "X_test_lda = lda.fit(X_train_lda, y_train)\n",
    "lr = LogisticRegression(multi_class='ovr', random_state=1,\n",
    "                        solver='lbfgs')\n",
    "lr = lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test_lda)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c3016041",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=LinearDiscriminantAnalysis(n_components=2).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[204], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(X_test_lda)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test, predictions))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:932\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_2d:\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;66;03m# If input is scalar raise error\u001b[39;00m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 932\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got scalar array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    935\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    937\u001b[0m         )\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=LinearDiscriminantAnalysis(n_components=2).\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "predictions = lr.predict(X_test_lda)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907d73ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
